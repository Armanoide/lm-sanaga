┌──────────────────────────────────────────────────────────────┐
│                      1. Load Prompt (Vec<u32>)               │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
                Convert to MLX Tensor (input)
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│               2. Load Weights from .safetensors              │
│                                                              │
│ read_safetensors_weights(path) ──> HashMap<String, Tensor>  │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│              3. Build Model Layers with LinearBuilder        │
│ LinearBuilder { dims... }.build()                            │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│       4. Assign Weights to Layers with .copy_from()          │
│      (per weight: linear.weight.copy_from(&tensor))          │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│            5. Run Model Forward(input: Tensor)               │
│          Output: logits [1, seq_len, vocab_size]             │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│   6. Greedy or Sampling Decode Next Token from Logits        │
│          e.g., argmax(logits[-1]) = next_token_id            │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│ 7. Append Token → Rerun Model → Repeat until max_tokens or EOS│
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌──────────────────────────────────────────────────────────────┐
│         8. Final Output: Vec<u32> of generated tokens         │
└──────────────────────────────────────────────────────────────┘
                           │
                           ▼
       (Optional: decode with tokenizer to readable text)
